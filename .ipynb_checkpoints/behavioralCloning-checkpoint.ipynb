{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.utils.data.dataset as datautil\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do this twice for it to work for some reason\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select model from cloningCNN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloningCNN import CloningCNN\n",
    "from cloningCNN import MultiSequentialCNN\n",
    "from cloningCNN import ResNet\n",
    "\n",
    "usingResNet = False\n",
    "usingQuad = True #using the 4 images in 1 or just individual images\n",
    "earlyIntegration = True\n",
    "\n",
    "if usingResNet:\n",
    "    model = ResNet()\n",
    "else:\n",
    "    if usingQuad:\n",
    "        model = CloningCNN('deeper', dropout=0.5, inChannels=12)\n",
    "    else:\n",
    "        model = CloningCNN('deeper', dropout=0.5, inChannels=3)\n",
    "# model = MultiSequentialCNN(netType='original', dropout=0) #this is drop probability\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed dataset mean and standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if usingResNet:\n",
    "    dset_mean = np.load(\"data/stats/dsetMean_ResNet.npy\")\n",
    "    dset_std = np.load(\"data/stats/dsetStd_ResNet.npy\")\n",
    "else:\n",
    "    dset_mean = np.load(\"data/stats/dsetMean.npy\")\n",
    "    dset_std = np.load(\"data/stats/dsetStd.npy\")\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.array(np.round(dset_mean), dtype=np.uint8))\n",
    "plt.title(\"Mean image\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.array(np.round(dset_std), dtype=np.uint8))\n",
    "plt.title(\"Std image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch expects the data shape to be CxHxW (instead of the current HxWxC) so we reshape the mean and std image here, then use them to calculate the means for the three color channels. For images in the training data, this transposition is handled when the dataset object applies the ToTensor() transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_mean = np.transpose(dset_mean, (2,0,1))\n",
    "dset_std = np.transpose(dset_std, (2,0,1))\n",
    "print(dset_mean.shape, dset_std.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, calculate the mean and std over the three image channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_means = dset_mean.mean(axis=(1,2)) / 255\n",
    "channel_stds = dset_mean.std(axis=(1,2)) / 255\n",
    "\n",
    "print(\"Per-channel means:\")\n",
    "print(channel_means)\n",
    "print(\"Per-channel stds:\")\n",
    "print(channel_stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize dataset and data loader objects\n",
    "Use the channel mean and std to define a normalization transform which our dataset object will apply to each of its images upon loading them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(channel_means, channel_stds)\n",
    "])\n",
    "\n",
    "# dataset = datasets.DatasetFolder(root='data/classes/normalized', extensions=['npy'], loader=np.load, transform=image_transform)\n",
    "if usingQuad:\n",
    "    if usingResNet:\n",
    "        dataset = datasets.ImageFolder(root='data/classes/224scaledQuad', transform=image_transform)\n",
    "    else:\n",
    "        dataset = datasets.ImageFolder(root='data/classes/downscaledQuad', transform=image_transform)\n",
    "else:\n",
    "    if usingResNet:\n",
    "        dataset = datasets.ImageFolder(root='data/classes/224scaledIndiv', transform=image_transform)\n",
    "    else:\n",
    "        dataset = datasets.ImageFolder(root='data/classes/downscaledIndiv', transform=image_transform)\n",
    "    \n",
    "num_train = len(dataset)\n",
    "print(\"Training set has {} examples.\".format(num_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the full dataset into train and val randomly (seeded), then create data loader objects for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val = num_train // 10\n",
    "permutation = np.random.RandomState(seed=0).permutation(num_train)\n",
    "\n",
    "val_dataset = datautil.Subset(dataset, permutation[:num_val])\n",
    "train_dataset = datautil.Subset(dataset, permutation[num_val:])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           sampler=sampler.SubsetRandomSampler(range(num_train-num_val)))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           sampler=sampler.SubsetRandomSampler(range(num_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show an image and its label from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(\"Train image shape: \", images[0].shape)\n",
    "\n",
    "# plt.imshow((images[0].numpy() * dset_std/255 + dset_mean/255).transpose(1,2,0))\n",
    "plt.imshow((images[0].numpy() * channel_stds.reshape((3,1,1)) + channel_means.reshape((3,1,1))).transpose(1,2,0))\n",
    "\n",
    "labelNames = {0:\"Up\",1:\"Right\",2:\"Down\",3:\"Left\"}\n",
    "_ = plt.title(labelNames[labels[0].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_accuracy(loader, model, name): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            if usingQuad:\n",
    "                if usingResNet:\n",
    "                    split = (x[:,:,:,:224],x[:,:,:,224:448],x[:,:,:,448:672],x[:,:,:,672:896])\n",
    "                else:\n",
    "                    split = (x[:,:,:,:180],x[:,:,:,180:360],x[:,:,:,360:540],x[:,:,:,540:720])\n",
    "                    \n",
    "                if earlyIntegration:\n",
    "                    scores = model(torch.cat(split, dim=1))\n",
    "                else:\n",
    "                    scores = model(split)\n",
    "            else:\n",
    "                scores = model(x)\n",
    "            \n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('%s set: Got %d / %d correct (%.2f)' % (name, num_correct, num_samples, 100 * acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant to control how frequently we check val loss\n",
    "print_every = (num_train/64)//2 + 1 # \n",
    "\n",
    "def train_model(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    train_losses, train_accuracy, val_accuracy = [], [], []\n",
    "    best_val = 0\n",
    "    timestamp = time.strftime(\"%m_%d_T%H_%M\") # time started training, best val model will be saved with this\n",
    "    modelFile = None\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        print('Epoch {}'.format(e))\n",
    "        for t, (x, y) in enumerate(train_loader):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            if usingQuad:\n",
    "                if usingResNet:\n",
    "                    split = (x[:,:,:,:224],x[:,:,:,224:448],x[:,:,:,448:672],x[:,:,:,672:896])\n",
    "                else:\n",
    "                    split = (x[:,:,:,:180],x[:,:,:,180:360],x[:,:,:,360:540],x[:,:,:,540:720])\n",
    "                    \n",
    "                if earlyIntegration:\n",
    "                    scores = model(torch.cat(split, dim=1))\n",
    "                else:\n",
    "                    scores = model(split)\n",
    "            else:\n",
    "                scores = model(x)\n",
    "            \n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                val = check_model_accuracy(val_loader, model, 'Val')\n",
    "                if val > best_val:\n",
    "                    # save the best model over the course of training\n",
    "                    modelFile = 'models/cloningCNN_val{}_{}.pt'.format(int(val*100),timestamp)\n",
    "                    torch.save(model.state_dict(), modelFile)\n",
    "                    best_val = val\n",
    "                if t == 0:\n",
    "                    train_accuracy.append(check_model_accuracy(train_loader, model, 'Train'))\n",
    "                    val_accuracy.append(val)\n",
    "                print()\n",
    "        \n",
    "    return (train_losses, train_accuracy, val_accuracy, modelFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_losses, train_accuracy, val_accuracy, modelFile = train_model(model, optimizer, epochs=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and accuracy plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(dpi=300)\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"Loss\")\n",
    "# plt.savefig('demos/BestResnetLoss2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(dpi=300)\n",
    "plt.plot(train_accuracy)\n",
    "plt.plot(val_accuracy)\n",
    "plt.title(\"Train vs. Val Accuracy\")\n",
    "# plt.savefig('demos/BestResnetAccuracy2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the best model saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(modelFile))\n",
    "model.to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_accuracy(val_loader, model, 'Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
